{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# 加载预训练的 YOLOv11n 模型\n",
    "model_path =  '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/train8/weights/best.pt'#'/home/szh/work/Weed_Detection/ultralytics-main/yolo11n.pt'\n",
    "model = YOLO(model_path)\n",
    "source = '/home/szh/work/Weed_Detection/test/images/19117.png' #'/home/szh/work/Weed_Detection/cat.jpg' #更改为自己的图片路径\n",
    "# 运行推理，并附加参数\n",
    "model.predict(source, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集格式转yolo格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "# 定义目标label的类ID\n",
    "LABELS = {\n",
    "    \"weed\": 0,  # 其他所有的 label 统一为 \"weed\"，class_id 为 0\n",
    "    \"mq\": 1     # mq 对应的 class_id 为 1\n",
    "}\n",
    "\n",
    "def convert_to_yolo_format(points, img_width, img_height):\n",
    "    # YOLO格式: class_id center_x center_y width height\n",
    "    # points 是一个包含两个坐标 [(x1, y1), (x2, y2)]，表示的是矩形的两个点\n",
    "    x_1, y_1 = points[0]\n",
    "    x_2, y_2 = points[1]\n",
    "\n",
    "    r = math.sqrt((x_2 - x_1) ** 2 + (y_2 - y_1) ** 2)\n",
    "    # 外接正方形的左上角和右下角\n",
    "    x1 = x_1 - r\n",
    "    y1 = y_1 - r\n",
    "    \n",
    "    x2 = x_1 + r\n",
    "    y2 = y_1 + r\n",
    "\n",
    "\n",
    "    # 将矩形的两个点转换为边界框的中心点和宽高\n",
    "    center_x = (x1 + x2) / 2.0 / img_width\n",
    "    center_y = (y1 + y2) / 2.0 / img_height\n",
    "\n",
    "    width = (2*r) / img_width\n",
    "    height = (2*r) / img_height\n",
    "\n",
    "    return center_x, center_y, width, height\n",
    "\n",
    "def process_json_label(json_file, output_dir):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    img_width = data['imageWidth']\n",
    "    img_height = data['imageHeight']\n",
    "    \n",
    "    # 获取图像的文件名 (无后缀)\n",
    "    image_filename = os.path.splitext(os.path.basename(data['imagePath']))[0]\n",
    "\n",
    "    # 输出的YOLO格式标签文件路径\n",
    "    yolo_txt_path = os.path.join(output_dir, f\"{image_filename}.txt\")\n",
    "    \n",
    "    # 打开文件写入YOLO格式的标签\n",
    "    with open(yolo_txt_path, 'w') as yolo_file:\n",
    "        for shape in data['shapes']:\n",
    "            label = shape['label']\n",
    "            \n",
    "            # 只检测 \"mq\"，其余的都统一成 \"weed\"\n",
    "            if label == 'mq':\n",
    "                class_id = LABELS['mq']\n",
    "            else:\n",
    "                class_id = LABELS['weed']\n",
    "            \n",
    "            # 解析 points，转换成 YOLO 格式\n",
    "            points = shape['points']\n",
    "            center_x, center_y, width, height = convert_to_yolo_format(points, img_width, img_height)\n",
    "            \n",
    "            # 写入文件，格式: class_id center_x center_y width height\n",
    "            yolo_file.write(f\"{class_id} {center_x} {center_y} {width} {height}\\n\")\n",
    "\n",
    "def convert_dataset(json_dir, output_dir):\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 遍历所有的json文件\n",
    "    for filename in os.listdir(json_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            json_file = os.path.join(json_dir, filename)\n",
    "            process_json_label(json_file, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入的JSON标注文件目录\n",
    "    json_dir = \"/home/szh/work/Weed_Detection/train/labels\"\n",
    "    # 输出的YOLO格式标签的目录\n",
    "    output_dir = \"/home/szh/work/Weed_Detection/train/labels_process\"\n",
    "    \n",
    "    convert_dataset(json_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def process_files(input_path, output_path):\n",
    "    total_deleted_lines = 0\n",
    "    log_entries = []\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    # 遍历输入路径下的所有 txt 文件\n",
    "    for filename in os.listdir(input_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            input_file_path = os.path.join(input_path, filename)\n",
    "            output_file_path = os.path.join(output_path, filename)\n",
    "            \n",
    "            with open(input_file_path, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # 保存更新后的内容\n",
    "            updated_lines = []\n",
    "            deleted_lines_count = 0\n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 4:\n",
    "                    fourth_value = float(parts[3])  # 取第四个数字\n",
    "                    x_value = float(parts[1])\n",
    "                    y_value = float(parts[2])\n",
    "                    if fourth_value < 0.025:\n",
    "                        deleted_lines_count += 1\n",
    "                        log_entries.append(f\"File: {filename}, Line {i+1}: Deleted (Fourth value < 0.025)\")\n",
    "                    else:\n",
    "                        updated_lines.append(line)\n",
    "            \n",
    "            # 保存更新后的文件到输出路径\n",
    "            with open(output_file_path, \"w\") as file:\n",
    "                file.writelines(updated_lines)\n",
    "\n",
    "            total_deleted_lines += deleted_lines_count\n",
    "\n",
    "    # 输出日志和删除的行数\n",
    "    if log_entries:\n",
    "        for log in log_entries:\n",
    "            print(log)\n",
    "    print(f\"Total lines deleted across all files: {total_deleted_lines}\")\n",
    "\n",
    "# Example usage:\n",
    "input_path = \"/home/szh/work/Weed_Detection/train/data_Division_preprocess/train_Augment/labels\"  # 输入目录路径\n",
    "output_path = \"/home/szh/work/Weed_Detection/train/data_Division_preprocess/train_Augment/labels_pre\"  # 输出目录路径\n",
    "process_files(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "\"\"\" \n",
    "Created on 2023-04-01 9:08 \n",
    "@author: Fan yi ming \n",
    "Func: 对于目标检测的数据增强[YOLO]（特点是数据增强后标签也要更改）\n",
    "review：常用的数据增强方式； \n",
    "        1.翻转：左右和上下翻转，随机翻转 \n",
    "        2.随机裁剪，图像缩放 \n",
    "        3.改变色调 \n",
    "        4.添加噪声 \n",
    "注意： boxes的标签和坐标一个是int，一个是float，存放的时候要注意处理方式。 \n",
    "参考：https://github.com/REN-HT/Data-Augmentation/blob/main/data_augmentation.py \n",
    "\"\"\"\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    " \n",
    " \n",
    "class DataAugmentationOnDetection:\n",
    "    def __init__(self):\n",
    "        super(DataAugmentationOnDetection, self).__init__()\n",
    " \n",
    "    # 以下的几个参数类型中，image的类型全部如下类型\n",
    "    # 参数类型： image：Image.open(path)\n",
    "    def resize_keep_ratio(self, image, boxes, target_size):\n",
    "        \"\"\"\n",
    "            参数类型： image：Image.open(path)， boxes:Tensor， target_size:int\n",
    "            功能：将图像缩放到size尺寸，调整相应的boxes,同时保持长宽比（最长的边是target size\n",
    "        \"\"\"\n",
    "        old_size = image.size[0:2]  # 原始图像大小\n",
    "        # 取最小的缩放比例\n",
    "        ratio = min(float(target_size) / (old_size[i]) for i in range(len(old_size)))  # 计算原始图像宽高与目标图像大小的比例，并取其中的较小值\n",
    "        new_size = tuple([int(i * ratio) for i in old_size])  # 根据上边求得的比例计算在保持比例前提下得到的图像大小\n",
    "        # boxes 不用变化，因为是等比例变化\n",
    "        return image.resize(new_size, Image.BILINEAR), boxes\n",
    " \n",
    "    def resizeDown_keep_ratio(self, image, boxes, target_size):\n",
    "        \"\"\" 与上面的函数功能类似，但它只降低图片的尺寸，不会扩大图片尺寸\"\"\"\n",
    "        old_size = image.size[0:2]  # 原始图像大小\n",
    "        # 取最小的缩放比例\n",
    "        ratio = min(float(target_size) / (old_size[i]) for i in range(len(old_size)))  # 计算原始图像宽高与目标图像大小的比例，并取其中的较小值\n",
    "        ratio = min(ratio, 1)\n",
    "        new_size = tuple([int(i * ratio) for i in old_size])  # 根据上边求得的比例计算在保持比例前提下得到的图像大小\n",
    " \n",
    "        # boxes 不用变化，因为是等比例变化\n",
    "        return image.resize(new_size, Image.BILINEAR), boxes\n",
    " \n",
    "    def resize(self, img, boxes, size):\n",
    "        # ---------------------------------------------------------\n",
    "        # 类型为 img=Image.open(path)，boxes:Tensor，size:int\n",
    "        # 功能为：将图像长和宽缩放到指定值size，并且相应调整boxes\n",
    "        # ---------------------------------------------------------\n",
    "        return img.resize((size, size), Image.BILINEAR), boxes\n",
    " \n",
    "    def random_flip_horizon(self, img, boxes, h_rate=1):\n",
    "        # -------------------------------------\n",
    "        # 随机水平翻转\n",
    "        # -------------------------------------\n",
    "        if np.random.random() < h_rate:\n",
    "            transform = transforms.RandomHorizontalFlip(p=1)\n",
    "            img = transform(img)\n",
    "            if len(boxes) > 0:\n",
    "                x = 1 - boxes[:, 1]\n",
    "                boxes[:, 1] = x\n",
    "        return img, boxes\n",
    " \n",
    "    def random_flip_vertical(self, img, boxes, v_rate=1):\n",
    "        # 随机垂直翻转\n",
    "        if np.random.random() < v_rate:\n",
    "            transform = transforms.RandomVerticalFlip(p=1)\n",
    "            img = transform(img)\n",
    "            if len(boxes) > 0:\n",
    "                y = 1 - boxes[:, 2]\n",
    "                boxes[:, 2] = y\n",
    "        return img, boxes\n",
    " \n",
    "    def center_crop(self, img, boxes, target_size=None):\n",
    "        # -------------------------------------\n",
    "        # 中心裁剪 ，裁剪成 (size, size) 的正方形, 仅限图形，w,h\n",
    "        # 这里用比例是很难算的，转成x1,y1, x2, y2格式来计算\n",
    "        # -------------------------------------\n",
    "        w, h = img.size\n",
    "        size = min(w, h)\n",
    "        if len(boxes) > 0:\n",
    "            # 转换到xyxy格式\n",
    "            label = boxes[:, 0].reshape([-1, 1])\n",
    "            x_, y_, w_, h_ = boxes[:, 1], boxes[:, 2], boxes[:, 3], boxes[:, 4]\n",
    "            x1 = (w * x_ - 0.5 * w * w_).reshape([-1, 1])\n",
    "            y1 = (h * y_ - 0.5 * h * h_).reshape([-1, 1])\n",
    "            x2 = (w * x_ + 0.5 * w * w_).reshape([-1, 1])\n",
    "            y2 = (h * y_ + 0.5 * h * h_).reshape([-1, 1])\n",
    "            boxes_xyxy = torch.cat([x1, y1, x2, y2], dim=1)\n",
    "            # 边框转换\n",
    "            if w > h:\n",
    "                boxes_xyxy[:, [0, 2]] = boxes_xyxy[:, [0, 2]] - (w - h) / 2\n",
    "            else:\n",
    "                boxes_xyxy[:, [1, 3]] = boxes_xyxy[:, [1, 3]] - (h - w) / 2\n",
    "            in_boundary = [i for i in range(boxes_xyxy.shape[0])]\n",
    "            for i in range(boxes_xyxy.shape[0]):\n",
    "                # 判断x是否超出界限\n",
    "                if (boxes_xyxy[i, 0] < 0 and boxes_xyxy[i, 2] < 0) or (boxes_xyxy[i, 0] > size and boxes_xyxy[i, 2] > size):\n",
    "                    in_boundary.remove(i)\n",
    "                # 判断y是否超出界限\n",
    "                elif (boxes_xyxy[i, 1] < 0 and boxes_xyxy[i, 3] < 0) or (boxes_xyxy[i, 1] > size and boxes_xyxy[i, 3] > size):\n",
    "                    in_boundary.append(i)\n",
    "            boxes_xyxy = boxes_xyxy[in_boundary]\n",
    "            boxes = boxes_xyxy.clamp(min=0, max=size).reshape([-1, 4])  # 压缩到固定范围\n",
    "            label = label[in_boundary]\n",
    "            # 转换到YOLO格式\n",
    "            x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n",
    "            xc = ((x1 + x2) / (2 * size)).reshape([-1, 1])\n",
    "            yc = ((y1 + y2) / (2 * size)).reshape([-1, 1])\n",
    "            wc = ((x2 - x1) / size).reshape([-1, 1])\n",
    "            hc = ((y2 - y1) / size).reshape([-1, 1])\n",
    "            boxes = torch.cat([xc, yc, wc, hc], dim=1)\n",
    "        # 图像转换 \n",
    "        transform = transforms.CenterCrop(size) \n",
    "        img = transform(img) \n",
    "        if target_size: \n",
    "            img = img.resize((target_size, target_size), Image.BILINEAR) \n",
    "        if len(boxes) > 0: \n",
    "            return img, torch.cat([label.reshape([-1, 1]), boxes], dim=1) \n",
    "        else: \n",
    "            return img, boxes \n",
    "  \n",
    "    # ------------------------------------------------------\n",
    "    # 以下img皆为Tensor类型\n",
    "    # ------------------------------------------------------\n",
    " \n",
    "    def random_bright(self, img, u=120, p=1): \n",
    "        # -------------------------------------\n",
    "        # 随机亮度变换 \n",
    "        # -------------------------------------\n",
    "        if np.random.random() < p:\n",
    "            alpha=np.random.uniform(-u, u)/255\n",
    "            img += alpha\n",
    "            img=img.clamp(min=0.0, max=1.0)\n",
    "        return img\n",
    " \n",
    "    def random_contrast(self, img, lower=0.5, upper=1.5, p=1):\n",
    "        # -------------------------------------\n",
    "        # 随机增强对比度 \n",
    "        # -------------------------------------\n",
    "        if np.random.random() < p:\n",
    "            alpha=np.random.uniform(lower, upper)\n",
    "            img*=alpha\n",
    "            img=img.clamp(min=0, max=1.0)\n",
    "        return img\n",
    " \n",
    "    def random_saturation(self, img,lower=0.5, upper=1.5, p=1):\n",
    "        # 随机饱和度变换，针对彩色三通道图像，中间通道乘以一个值\n",
    "        if np.random.random() < p: \n",
    "            alpha=np.random.uniform(lower, upper) \n",
    "            img[1]=img[1]*alpha \n",
    "            img[1]=img[1].clamp(min=0,max=1.0) \n",
    "        return img \n",
    " \n",
    "    def add_gasuss_noise(self, img, mean=0, std=0.1): \n",
    "        noise=torch.normal(mean,std,img.shape) \n",
    "        img+=noise \n",
    "        img=img.clamp(min=0, max=1.0) \n",
    "        return img \n",
    " \n",
    "    def add_salt_noise(self, img):\n",
    "        noise=torch.rand(img.shape)\n",
    "        alpha=np.random.random()/5 + 0.7\n",
    "        img[noise[:,:,:]>alpha]=1.0\n",
    "        return img\n",
    " \n",
    "    def add_pepper_noise(self, img):\n",
    "        noise=torch.rand(img.shape)\n",
    "        alpha=np.random.random()/5 + 0.7\n",
    "        img[noise[:, :, :]>alpha]=0\n",
    "        return img\n",
    " \n",
    " \n",
    "def plot_pics(img, boxes):\n",
    "    # 显示图像和候选框，img是Image.Open()类型, boxes是Tensor类型\n",
    "    plt.imshow(img)\n",
    "    label_colors = [(213, 110, 89)]\n",
    "    w, h = img.size\n",
    "    for i in range(boxes.shape[0]):\n",
    "        box = boxes[i, 1:]\n",
    "        xc, yc, wc, hc = box\n",
    "        x = w * xc - 0.5 * w * wc\n",
    "        y = h * yc - 0.5 * h * hc\n",
    "        box_w, box_h = w * wc, h * hc\n",
    "        plt.gca().add_patch(plt.Rectangle(xy=(x, y), width=box_w, height=box_h,\n",
    "                                          edgecolor=[c / 255 for c in label_colors[0]],\n",
    "                                          fill=False, linewidth=2))\n",
    "    plt.show()\n",
    " \n",
    "def get_image_list(image_path):\n",
    "    # 根据图片文件，查找所有图片并返回列表\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(image_path):\n",
    "        for special_file in files:\n",
    "            special_file = special_file[0: len(special_file)]\n",
    "            files_list.append(special_file)\n",
    "    return files_list\n",
    " \n",
    "def get_label_file(label_path, image_name):\n",
    "    # 根据图片信息，查找对应的label\n",
    "    fname = os.path.join(label_path, image_name[0: len(image_name)-4]+\".txt\")\n",
    "    data2 = []\n",
    "    if not os.path.exists(fname):\n",
    "        return data2\n",
    "    if os.path.getsize(fname) == 0:\n",
    "        return data2\n",
    "    else:\n",
    "        with open(fname, 'r', encoding='utf-8') as infile:\n",
    "            # 读取并转换标签\n",
    "            for line in infile:\n",
    "                data_line = line.strip(\"\\n\").split()\n",
    "                data2.append([float(i) for i in data_line])\n",
    "    return data2\n",
    " \n",
    " \n",
    "def save_Yolo(img, boxes, save_path, prefix, image_name):\n",
    "    # img: 需要时Image类型的数据， prefix 前缀\n",
    "    # 将结果保存到save path指示的路径中\n",
    "    if not os.path.exists(save_path) or \\\n",
    "            not os.path.exists(os.path.join(save_path, \"images\")):\n",
    "        os.makedirs(os.path.join(save_path, \"images\"))\n",
    "        os.makedirs(os.path.join(save_path, \"labels\"))\n",
    "    try:\n",
    "        img.save(os.path.join(save_path, \"images\", prefix + image_name))\n",
    "        with open(os.path.join(save_path, \"labels\", prefix + image_name[0:len(image_name)-4] + \".txt\"), 'w', encoding=\"utf-8\") as f:\n",
    "            if len(boxes) > 0:  # 判断是否为空\n",
    "                # 写入新的label到文件中\n",
    "                for data in boxes:\n",
    "                    str_in = \"\"\n",
    "                    for i, a in enumerate(data):\n",
    "                        if i == 0:\n",
    "                            str_in += str(int(a))\n",
    "                        else:\n",
    "                            str_in += \" \" + str(float(a))\n",
    "                    f.write(str_in + '\\n')\n",
    "    except:\n",
    "        print(\"ERROR: \", image_name, \" is bad.\")\n",
    " \n",
    " \n",
    "def runAugumentation(image_path, label_path, save_path):\n",
    "    image_list = get_image_list(image_path)\n",
    "    for image_name in image_list:\n",
    "        print(\"dealing: \" + image_name)\n",
    "        img = Image.open(os.path.join(image_path, image_name))\n",
    "        boxes = get_label_file(label_path, image_name)\n",
    "        boxes = torch.tensor(boxes)\n",
    "        # 下面是执行的数据增强功能，可自行选择\n",
    "        # Image类型的参数\n",
    "        DAD = DataAugmentationOnDetection()\n",
    " \n",
    "        \"\"\" 尺寸变换   \"\"\"\n",
    "        # 缩小尺寸\n",
    "        # t_img, t_boxes = DAD.resizeDown_keep_ratio(img, boxes, 1024)\n",
    "        # save_Yolo(t_img, boxes, save_path, prefix=\"rs_\", image_name=image_name)\n",
    "        # 水平旋转\n",
    "        t_img, t_boxes = DAD.random_flip_horizon(img, boxes.clone())\n",
    "        save_Yolo(t_img, t_boxes, save_path, prefix=\"fh_\", image_name=image_name)\n",
    "        # 竖直旋转\n",
    "        t_img, t_boxes = DAD.random_flip_vertical(img, boxes.clone())\n",
    "        save_Yolo(t_img, t_boxes, save_path, prefix=\"fv_\", image_name=image_name)\n",
    "        # center_crop\n",
    "        t_img, t_boxes = DAD.center_crop(img, boxes.clone(), 1024)\n",
    "        save_Yolo(t_img, t_boxes, save_path, prefix=\"cc_\", image_name=image_name)\n",
    " \n",
    "        \"\"\" 图像变换，用tensor类型\"\"\"\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        to_image = transforms.ToPILImage()\n",
    "        img = to_tensor(img)\n",
    " \n",
    "        # random_bright\n",
    "        t_img, t_boxes = DAD.random_bright(img.clone()), boxes\n",
    "        save_Yolo(to_image(t_img), boxes, save_path, prefix=\"rb_\", image_name=image_name)\n",
    "        # random_contrast 对比度变化\n",
    "        t_img, t_boxes = DAD.random_contrast(img.clone()), boxes\n",
    "        save_Yolo(to_image(t_img), boxes, save_path, prefix=\"rc_\", image_name=image_name)\n",
    "        # random_saturation 饱和度变化\n",
    "        t_img, t_boxes = DAD.random_saturation(img.clone()), boxes\n",
    "        save_Yolo(to_image(t_img), boxes, save_path, prefix=\"rs_\", image_name=image_name)\n",
    "        # 高斯噪声\n",
    "        # t_img, t_boxes = DAD.add_gasuss_noise(img.clone()), boxes\n",
    "        # save_Yolo(to_image(t_img), boxes, save_path, prefix=\"gn_\", image_name=image_name)\n",
    "        # add_salt_noise\n",
    "        # t_img, t_boxes = DAD.add_salt_noise(img.clone()), boxes\n",
    "        # save_Yolo(to_image(t_img), boxes, save_path, prefix=\"sn_\", image_name=image_name)\n",
    "        # add_pepper_noise\n",
    "        # t_img, t_boxes = DAD.add_pepper_noise(img.clone()), boxes\n",
    "        # save_Yolo(to_image(t_img), boxes, save_path, prefix=\"pn_\", image_name=image_name)\n",
    " \n",
    "        print(\"end:     \" + image_name)\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # 图像和标签文件夹\n",
    "    image_path = '/home/szh/work/Weed_Detection/train/data_Division_preprocess/train/images'\n",
    "    label_path = '/home/szh/work/Weed_Detection/train/data_Division_preprocess/train/labels'\n",
    "    save_path = '/home/szh/work/Weed_Detection/train/data_Division_preprocess/train_Augment'         # 结果保存位置路径，可以是一个不存在的文件夹\n",
    "    # 运行\n",
    "    runAugumentation(image_path, label_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集的划分  训练集：验证集：测试集="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    " \n",
    "random.seed(0)  #随机种子，可自选开启\n",
    "def split_data(file_path, label_path, new_file_path, train_rate, val_rate, test_rate):\n",
    "\timages = os.listdir(file_path)\n",
    "\tlabels = os.listdir(label_path)\n",
    "\timages_no_ext = {os.path.splitext(image)[0]: image for image in images}\n",
    "\tlabels_no_ext = {os.path.splitext(label)[0]: label for label in labels}\n",
    "\tmatched_data = [(img, images_no_ext[img], labels_no_ext[img]) for img in images_no_ext if img in labels_no_ext]\n",
    " \n",
    "\tunmatched_images = [img for img in images_no_ext if img not in labels_no_ext]\n",
    "\tunmatched_labels = [label for label in labels_no_ext if label not in images_no_ext]\n",
    "\tif unmatched_images:\n",
    "\t\tprint(\"未匹配的图片文件:\")\n",
    "\t\tfor img in unmatched_images:\n",
    "\t\t\tprint(images_no_ext[img])\n",
    "\tif unmatched_labels:\n",
    "\t\tprint(\"未匹配的标签文件:\")\n",
    "\t\tfor label in unmatched_labels:\n",
    "\t\t\tprint(labels_no_ext[label])\n",
    " \n",
    "\trandom.shuffle(matched_data)\n",
    "\ttotal = len(matched_data)\n",
    "\ttrain_data = matched_data[:int(train_rate * total)]\n",
    "\tval_data = matched_data[int(train_rate * total):int((train_rate + val_rate) * total)]\n",
    "\ttest_data = matched_data[int((train_rate + val_rate) * total):]\n",
    " \n",
    "\t# 处理训练集\n",
    "\tfor img_name, img_file, label_file in train_data:\n",
    "\t\told_img_path = os.path.join(file_path, img_file)\n",
    "\t\told_label_path = os.path.join(label_path, label_file)\n",
    "\t\tnew_img_dir = os.path.join(new_file_path, 'train', 'images')\n",
    "\t\tnew_label_dir = os.path.join(new_file_path, 'train', 'labels')\n",
    "\t\tos.makedirs(new_img_dir, exist_ok=True)\n",
    "\t\tos.makedirs(new_label_dir, exist_ok=True)\n",
    "\t\tshutil.copy(old_img_path, os.path.join(new_img_dir, img_file))\n",
    "\t\tshutil.copy(old_label_path, os.path.join(new_label_dir, label_file))\n",
    "\t# 处理验证集\n",
    "\tfor img_name, img_file, label_file in val_data:\n",
    "\t\told_img_path = os.path.join(file_path, img_file)\n",
    "\t\told_label_path = os.path.join(label_path, label_file)\n",
    "\t\tnew_img_dir = os.path.join(new_file_path, 'val', 'images')\n",
    "\t\tnew_label_dir = os.path.join(new_file_path, 'val', 'labels')\n",
    "\t\tos.makedirs(new_img_dir, exist_ok=True)\n",
    "\t\tos.makedirs(new_label_dir, exist_ok=True)\n",
    "\t\tshutil.copy(old_img_path, os.path.join(new_img_dir, img_file))\n",
    "\t\tshutil.copy(old_label_path, os.path.join(new_label_dir, label_file))\n",
    "\t# 处理测试集\n",
    "\tfor img_name, img_file, label_file in test_data:\n",
    "\t\told_img_path = os.path.join(file_path, img_file)\n",
    "\t\told_label_path = os.path.join(label_path, label_file)\n",
    "\t\tnew_img_dir = os.path.join(new_file_path, 'test', 'images')\n",
    "\t\tnew_label_dir = os.path.join(new_file_path, 'test', 'labels')\n",
    "\t\tos.makedirs(new_img_dir, exist_ok=True)\n",
    "\t\tos.makedirs(new_label_dir, exist_ok=True)\n",
    "\t\tshutil.copy(old_img_path, os.path.join(new_img_dir, img_file))\n",
    "\t\tshutil.copy(old_label_path, os.path.join(new_label_dir, label_file))\n",
    "\tprint(\"数据集已划分完成\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\tfile_path = \"/home/szh/work/Weed_Detection/train/images\"  # 图片文件夹\n",
    "\tlabel_path = '/home/szh/work/Weed_Detection/train/labels'  # 标签文件夹\n",
    "\tnew_file_path = '/home/szh/work/Weed_Detection/train/data_Division' # 新数据存放位置\n",
    "\tsplit_data(file_path, label_path, new_file_path, train_rate=0.8, val_rate=0.2, test_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "if __name__ == '__main__': \n",
    "    model = YOLO('ultralytics/cfg/models/11/yolo11n.yaml')  # 从YAML建立一个新模型\n",
    "    model_path = '/home/szh/work/Weed_Detection/ultralytics-main/yolo11n.pt'\n",
    "    model.load(model_path)\n",
    "    print(\"开始训练： \")\n",
    "    # 训练模型\n",
    "    results = model.train(data='data.yaml',\n",
    "                      epochs=600, imgsz=640, device=0, optimizer='SGD', workers=8, batch=64, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = YOLO('ultralytics/cfg/models/11/yolo11n.yaml')  # 从YAML建立一个新模型\n",
    "    model_path = '/home/szh/work/Weed_Detection/ultralytics-main/yolo11n.pt'\n",
    "    model.load(model_path)\n",
    "    print(\"开始训练： \")\n",
    "\n",
    "    # 训练模型并存储结果\n",
    "    results = model.train(data='data.yaml',\n",
    "                          epochs=300,\n",
    "                          imgsz=640,\n",
    "                          device=0,\n",
    "                          optimizer='SGD',\n",
    "                          workers=8,\n",
    "                          batch=64,\n",
    "                          amp=False)\n",
    "\n",
    "    # 获取训练结果\n",
    "    metrics = results.results\n",
    "\n",
    "    # 从metrics中提取数据\n",
    "    epochs = range(1, len(metrics['metrics/precision']) + 1)\n",
    "    train_loss = metrics['train/loss']\n",
    "    val_loss = metrics['val/loss']\n",
    "    precision = metrics['metrics/precision']\n",
    "    recall = metrics['metrics/recall']\n",
    "    mAP_05 = metrics['metrics/mAP_0.5']\n",
    "    mAP_05_095 = metrics['metrics/mAP_0.5:0.95']\n",
    "\n",
    "    # 绘制loss曲线\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, precision, label='Precision')\n",
    "    plt.plot(epochs, recall, label='Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()\n",
    "    plt.title('Precision and Recall')\n",
    "\n",
    "    # 绘制mAP曲线\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, mAP_05, label='mAP@0.5')\n",
    "    plt.plot(epochs, mAP_05_095, label='mAP@0.5:0.95')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mAP')\n",
    "    plt.legend()\n",
    "    plt.title('Mean Average Precision (mAP)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 打印每个epoch后的loss和准确率信息以及所用时间\n",
    "    for i, (t_loss, v_loss, prec, rec, map50, map5095) in enumerate(zip(train_loss, val_loss, precision, recall, mAP_05, mAP_05_095)):\n",
    "        print(f\"Epoch {i+1}: Train Loss: {t_loss:.4f}, Val Loss: {v_loss:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, mAP@0.5: {map50:.4f}, mAP@0.5:0.95: {map5095:.4f}\")\n",
    "\n",
    "    # 打印训练总时间\n",
    "    print(f\"\\nTotal training time: {results.t['total'] / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练结果绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件的数据\n",
    "# 这里假设 result.csv 文件存放在你的工作目录下，或者提供文件的绝对路径\n",
    "file_path = '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/train79/results.csv'\n",
    "\n",
    "# 使用 pandas 读取 CSV 文件\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 绘制训练和验证损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 创建一个图，绘制训练和验证损\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(df['epoch'], df['train/box_loss'], label='train/box_loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val/box_loss'], label='val/box_loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Box Loss')\n",
    "plt.title('Box Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(df['epoch'], df['train/cls_loss'], label='train/cls_loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val/cls_loss'], label='val/cls_loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Class Loss')\n",
    "plt.title('Class Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(df['epoch'], df['train/dfl_loss'], label='train/dfl_loss', color='blue')\n",
    "plt.plot(df['epoch'], df['val/dfl_loss'], label='val/dfl_loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('DFL Loss')\n",
    "plt.title('DFL Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制其他指标（Precision, Recall, mAP50等）\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df['epoch'], df['metrics/precision(B)'], label='Precision', color='green')\n",
    "plt.plot(df['epoch'], df['metrics/recall(B)'], label='Recall', color='orange')\n",
    "plt.plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP50', color='purple')\n",
    "plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP50-95', color='brown')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Precision, Recall, mAP')\n",
    "plt.legend()\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "image_id =  3272\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir, image_file)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 运行推理\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 遍历推理结果\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/work/Weed_Detection/ultralytics-main/ultralytics/engine/model.py:547\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor:\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, args)\n",
      "File \u001b[0;32m~/work/Weed_Detection/ultralytics-main/ultralytics/engine/predictor.py:304\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize YOLO model with given parameters and set it to evaluation mode.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/Weed_Detection/ultralytics-main/ultralytics/nn/autobackend.py:145\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, batch, fuse, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# In-memory PyTorch model\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nn_module:\n\u001b[0;32m--> 145\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fuse:\n\u001b[1;32m    147\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfuse(verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/Weed_Detection/ultralytics-main/ultralytics/nn/tasks.py:258\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    Applies a function to all the tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m        (BaseModel): An updated BaseModel object.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Detect()\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Detect):  \u001b[38;5;66;03m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov11/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import pdb\n",
    "import torch\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "# torch.cuda.set_device(3)\n",
    "\n",
    "# 加载训练好的模型\n",
    "best_model_path = '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_4_dataset/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# 测试图像目录\n",
    "source_dir = '/home/szh/work/Weed_Detection/test/images'  # 修改为自己的图片路径\n",
    "\n",
    "# 获取目录下所有图像文件\n",
    "image_files = [f for f in os.listdir(source_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(len(image_files))\n",
    "\n",
    "# 准备保存的列表\n",
    "output_data = []\n",
    "\n",
    "# 遍历每个图像文件并进行推理\n",
    "j=0\n",
    "for image_file in image_files:\n",
    "    # 提取文件名作为 image_id（去掉扩展名）\n",
    "    image_id = os.path.splitext(image_file)[0]\n",
    "    print(\"image_id = \",image_id)\n",
    "\n",
    "    # 生成图像的完整路径\n",
    "    image_path = os.path.join(source_dir, image_file)\n",
    "    \n",
    "    # 运行推理\n",
    "    results = model.predict(image_path)\n",
    "    \n",
    "    # 遍历推理结果\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # 获取预测到的所有框\n",
    "        for i, box in enumerate(boxes):\n",
    "            class_id = int(box.cls.item())  # 类别: 0 为 'weed', 1 为 'mq'\n",
    "            \n",
    "            # 获取 xyxy 坐标\n",
    "            xyxy = box.xyxy[0].cpu().numpy()  # 将 Tensor 转换为 NumPy 数组\n",
    "            \n",
    "            # 提取坐标\n",
    "            x_min = int(xyxy[0])  # 左上角 X 坐标\n",
    "            y_min = int(xyxy[1])  # 左上角 Y 坐标\n",
    "            x_max = int(xyxy[2])  # 右下角 X 坐标\n",
    "            y_max = int(xyxy[3])  # 右下角 Y 坐标\n",
    "            \n",
    "            # 计算宽度和高度\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            \n",
    "            # 添加到输出数据\n",
    "            j=j+1\n",
    "            output_data.append([j, image_id, class_id, x_min, y_min, width, height])\n",
    "            \n",
    "\n",
    "# 将数据保存为 CSV 格式\n",
    "df = pd.DataFrame(output_data, columns=['ID', 'image_id', 'class_id', 'x_min', 'y_min', 'width', 'height'])\n",
    "df.to_csv('/home/szh/work/Weed_Detection/test/output_predictions_split_4.csv', index=False)\n",
    "\n",
    "print(\"预测结果已保存到 '/home/szh/work/Weed_Detection/test/output_predictions_split_4.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5折交叉验证非极大值抑制集成测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from torchvision.ops import nms  # NMS function from PyTorch\n",
    "\n",
    "# Paths to your five models\n",
    "model_paths = [\n",
    "    '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_1_dataset/weights/best.pt',\n",
    "    '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_2_dataset/weights/best.pt',\n",
    "    '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_3_dataset/weights/best.pt',\n",
    "    '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_4_dataset/weights/best.pt',\n",
    "    '/home/szh/work/Weed_Detection/ultralytics-main/runs/detect/split_5_dataset/weights/best.pt'\n",
    "]\n",
    "\n",
    "# Load models\n",
    "models = [YOLO(path) for path in model_paths]\n",
    "\n",
    "# Directory for test images\n",
    "source_dir = '/home/szh/work/Weed_Detection/test/images'\n",
    "image_files = [f for f in os.listdir(source_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "output_data = []\n",
    "j = 0\n",
    "\n",
    "# Define NMS threshold\n",
    "nms_threshold = 0.7\n",
    "\n",
    "# Process each image\n",
    "for image_file in image_files:\n",
    "    image_id = os.path.splitext(image_file)[0]\n",
    "    image_path = os.path.join(source_dir, image_file)\n",
    "    \n",
    "    # Collect predictions from all models\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    classes_list = []\n",
    "\n",
    "    for model in models:\n",
    "        results = model.predict(image_path)\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                class_id = int(box.cls.item())\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                score = float(box.conf)  # Confidence score\n",
    "\n",
    "                x_min, y_min, x_max, y_max = map(int, xyxy)\n",
    "                boxes_list.append([x_min, y_min, x_max, y_max])\n",
    "                scores_list.append(score)\n",
    "                classes_list.append(class_id)\n",
    "\n",
    "    # Check if there are any boxes to process\n",
    "    if len(boxes_list) > 0:\n",
    "        # Convert lists to tensors for NMS processing\n",
    "        boxes_tensor = torch.tensor(boxes_list, dtype=torch.float32)\n",
    "        scores_tensor = torch.tensor(scores_list)\n",
    "        classes_tensor = torch.tensor(classes_list)\n",
    "\n",
    "        # Apply NMS\n",
    "        keep_indices = nms(boxes_tensor, scores_tensor, nms_threshold)\n",
    "\n",
    "        # Save NMS-filtered results\n",
    "        for idx in keep_indices:\n",
    "            j += 1\n",
    "            x_min, y_min, x_max, y_max = map(int, boxes_tensor[idx])\n",
    "            class_id = int(classes_tensor[idx].item())\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            output_data.append([j, image_id, class_id, x_min, y_min, width, height])\n",
    "\n",
    "# Save results to CSV\n",
    "df = pd.DataFrame(output_data, columns=['ID', 'image_id', 'class_id', 'x_min', 'y_min', 'width', 'height'])\n",
    "output_csv_path = '/home/szh/work/Weed_Detection/test/output_predictions_ensemble_0.7.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Ensemble prediction results saved to '{output_csv_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szh_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
